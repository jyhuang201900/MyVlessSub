import requests
import base64
import re
from urllib.parse import quote
from bs4 import BeautifulSoup

# --- é…ç½®åŒº ---
# VLESS æ¨¡æ¿æ–‡ä»¶è·¯å¾„
TEMPLATE_FILE = "vless_template.txt"
# æœ¬åœ°ä¼˜é€‰åŸŸåæ–‡ä»¶è·¯å¾„
DOMAINS_FILE = "domains.txt"
# ç”Ÿæˆçš„è®¢é˜…æ–‡ä»¶å
OUTPUT_FILE = "sub.txt"

# 1. åŸå§‹çš„è¿œç¨‹ä¼˜é€‰IPæº
REMOTE_IP_URL_1 = "https://raw.githubusercontent.com/barry-far/V2ray-Configs/main/All_IPs_port_443.txt"

# 2. åŠ¨æ€IPæº
DYNAMIC_IP_URL = "https://stock.hostmonit.com/CloudFlareYes"

# 3. GitHubä¼˜é€‰IPæº
GITHUB_IP_URL = "https://raw.githubusercontent.com/qwer-search/bestip/refs/heads/main/kejilandbestip.txt"
# --- é…ç½®åŒºç»“æŸ ---

def fetch_from_file(file_path):
    """ä»æœ¬åœ°æ–‡ä»¶è¯»å–åŸŸååˆ—è¡¨"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = [line.strip() for line in f if line.strip() and not line.strip().startswith('#')]
            print(f"âœ… ä»æœ¬åœ°æ–‡ä»¶ {file_path} è·å– {len(lines)} ä¸ªåŸŸåã€‚")
            return [{"domain": line, "type": "domain"} for line in lines]
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
        return []

def fetch_simple_ips(url):
    """ä»URLè·å–ç®€å•çš„IPåˆ—è¡¨"""
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        lines = [line.strip() for line in response.text.splitlines() if line.strip() and not line.strip().startswith('#')]
        print(f"âœ… ä» URL {url.split('/')[-1]} è·å– {len(lines)} ä¸ªIPã€‚")
        return [{"ip": line, "port": "443", "type": "ip", "name_suffix": line} for line in lines]
    except requests.RequestException as e:
        print(f"âŒ ä» URL {url.split('/')[-1]} è·å–IPå¤±è´¥: {e}")
        return []

def fetch_dynamic_ips(url):
    """ä» hostmonit è§£æåŠ¨æ€IPåœ°å€å’ŒISPä¿¡æ¯"""
    print("ğŸ”„ æ­£åœ¨ä» hostmonit è·å–åŠ¨æ€IP...")
    try:
        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'lxml')
        results = []
        for row in soup.find_all('tr')[1:]:
            cols = row.find_all('td')
            if len(cols) >= 5:
                ip = cols[0].text.strip()
                isp = cols[4].text.strip().replace(' ', '')
                if ip and isp:
                    results.append({
                        "ip": ip, 
                        "port": "443", 
                        "type": "ip", 
                        "name_suffix": isp
                    })
        
        print(f"âœ… æˆåŠŸä» hostmonit è·å– {len(results)} ä¸ªåŠ¨æ€IPã€‚")
        return results
    except Exception as e:
        print(f"âŒ hostmonit: è·å–æˆ–è§£æå¤±è´¥: {e}")
        return []

def fetch_github_ips(url):
    """ä» GitHub Raw URL è§£æå¸¦è‡ªå®šä¹‰ç«¯å£å’Œåç§°çš„IP"""
    print(f"ğŸ”„ æ­£åœ¨ä» GitHub è·å–ä¼˜é€‰IP...")
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        results = []
        regex = r'^([^:]+):(\d+)#(.*)$'
        for line in response.text.strip().split('\n'):
            match = re.match(regex, line.strip())
            if match:
                ip, port, name = match.groups()
                name_suffix = name.strip() or ip
                results.append({
                    "ip": ip,
                    "port": port,
                    "type": "ip",
                    "name_suffix": name_suffix
                })
        
        print(f"âœ… æˆåŠŸä» GitHub è·å– {len(results)} ä¸ªä¼˜é€‰IPã€‚")
        return results
    except requests.RequestException as e:
        print(f"âŒ GitHub: è·å–ä¼˜é€‰IPå¤±è´¥: {e}")
        return []

def generate_subscription():
    """ä¸»å‡½æ•°ï¼Œç”Ÿæˆè®¢é˜…æ–‡ä»¶"""
    # 1. è¯»å–VLESSæ¨¡æ¿
    try:
        with open(TEMPLATE_FILE, 'r', encoding='utf-8') as f:
            vless_template = f.read().strip()
            
            # ä»æ¨¡æ¿ä¸­æå–UUIDå’Œå…¶ä»–å‚æ•°
            uuid_match = re.search(r'vless://([^@]+)@', vless_template)
            uuid = uuid_match.group(1) if uuid_match else ""
            
            # æå–æŸ¥è¯¢å‚æ•°éƒ¨åˆ†
            params_match = re.search(r'\?(.+)#', vless_template)
            params = params_match.group(1) if params_match else ""
            
    except FileNotFoundError:
        print(f"âŒ è‡´å‘½é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡æ¿æ–‡ä»¶ {TEMPLATE_FILE}ã€‚ç¨‹åºå·²ç»ˆæ­¢ã€‚")
        return

    # 2. ä»æ‰€æœ‰æ¥æºè·å–åœ°å€
    print("\n--- å¼€å§‹è·å–æ‰€æœ‰èŠ‚ç‚¹åœ°å€ ---")
    domains = fetch_from_file(DOMAINS_FILE)
    simple_ips = fetch_simple_ips(REMOTE_IP_URL_1)
    dynamic_ips = fetch_dynamic_ips(DYNAMIC_IP_URL)
    github_ips = fetch_github_ips(GITHUB_IP_URL)
    
    # å°†æ‰€æœ‰æ¥æºçš„åœ°å€åˆå¹¶
    all_nodes = domains + simple_ips + dynamic_ips + github_ips
  
    if not all_nodes:
        print("\nâš ï¸ è­¦å‘Š: æœªèƒ½è·å–ä»»ä½•åœ°å€ä¿¡æ¯ï¼Œæ— æ³•ç”Ÿæˆè®¢é˜…ã€‚")
        return

    # 3. éå†èŠ‚ç‚¹ç”Ÿæˆé“¾æ¥
    node_links = []
    print("\nğŸš€ å¼€å§‹ç”ŸæˆèŠ‚ç‚¹é“¾æ¥...")
    
    for i, node in enumerate(all_nodes):
        # æ ¹æ®èŠ‚ç‚¹ç±»å‹ç”Ÿæˆä¸åŒçš„é“¾æ¥
        if node["type"] == "domain":
            # åŸŸåç±»å‹èŠ‚ç‚¹
            domain = node["domain"]
            server = "www.visa.com.sg"  # é»˜è®¤æœåŠ¡å™¨åœ°å€
            
            # æ„å»ºVLESSé“¾æ¥
            link = f"vless://{uuid}@{server}:443?encryption=none&security=tls&type=ws&host={domain}&sni={domain}&fp=random&path=/ï¼Ÿed=2560"
            name = f"Domain-{i+1:03d}-{domain}"
            
        elif node["type"] == "ip":
            # IPç±»å‹èŠ‚ç‚¹
            ip = node["ip"]
            port = node["port"]
            name_suffix = node.get("name_suffix", ip)
            
            # æ„å»ºVLESSé“¾æ¥
            link = f"vless://{uuid}@{ip}:{port}?{params}"
            name = f"IP-{i+1:03d}-{name_suffix}"
        
        # æ·»åŠ èŠ‚ç‚¹åç§°å¹¶è¿›è¡ŒURLç¼–ç 
        final_link = f"{link}#{quote(name)}"
        node_links.append(final_link)

    print(f"ğŸ‰ æ€»å…±ç”Ÿæˆäº† {len(node_links)} ä¸ªèŠ‚ç‚¹ã€‚")

    # 4. Base64ç¼–ç å¹¶å†™å…¥æ–‡ä»¶
    subscription_content = "\n".join(node_links)
    encoded_content = base64.b64encode(subscription_content.encode('utf-8')).decode('utf-8')

    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write(encoded_content)
        print(f"\nâœ¨ è®¢é˜…æ–‡ä»¶å·²æˆåŠŸç”Ÿæˆï¼âœ¨\n   æ–‡ä»¶å: {OUTPUT_FILE}\n")
    except Exception as e:
        print(f"âŒ å†™å…¥è®¢é˜…æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    generate_subscription()
